import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind, chi2_contingency, shapiro, kstest,f_oneway, kruskal

st.set_page_config(page_title="å·®å¼‚æ€§åˆ†æå·¥å…·", page_icon="ğŸ“Š", layout="wide")
st.title("å·®å¼‚æ€§åˆ†æå·¥å…·")
st.write("ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼Œè¿›è¡Œå·®å¼‚æ€§åˆ†æã€‚")
def highlight_p_value(val):
    try:
        if isinstance(val, str) and "<" not in val:
            p = float(val)
            if p < 0.05:
                return 'color: red; font-weight: bold'
    except:
        return ''
    return ''

def generate_test_data():
    np.random.seed(42)
    data = pd.DataFrame({
        "Age": np.random.randint(18, 65, size=100),
        "Weight": np.random.normal(loc=60, scale=10, size=100),
        "Height": np.random.normal(loc=170, scale=10, size=100),
        "Gender": np.random.choice([0, 1], size=100),
        "Education": np.random.choice([1, 2, 3], size=100),
        "GPA": np.random.choice([1, 2], size=100)
    })
    return data

def normality_test(data, column, n_threshold=5000):
    n = len(data[column].dropna())
    if n < n_threshold:
        stat, p_value = shapiro(data[column].dropna())
        method = "Shapiro-Wilk"
    else:
        stat, p_value = kstest(data[column].dropna(), 'norm')
        method = "Kolmogorov-Smirnov"
    return method, stat, p_value

def describe_data(data, column, normality_result):
    if normality_result["p_value"] > 0.05:
        mean = data[column].mean()
        std = data[column].std()
        return f"{mean:.2f} Â± {std:.2f}"
    else:
        q1 = data[column].quantile(0.25)
        q3 = data[column].quantile(0.75)
        return f"({q1:.2f} , {q3:.2f})"

def generate_three_line_table(data, group_column, quantitative_columns, categorical_columns):
    groups = sorted(data[group_column].dropna().unique())
    results = []

    # åˆ†ç»„å˜é‡ä¸ä½œä¸ºåˆ†æå˜é‡
    quantitative_columns = [col for col in quantitative_columns if col != group_column]
    categorical_columns = [col for col in categorical_columns if col != group_column]

    # å®šé‡å˜é‡åˆ†æ
    for value_column in quantitative_columns:
        row = {"variable": value_column}
        method, stat, p_value_normal = normality_test(data, value_column)
        is_normal = p_value_normal > 0.05

        for group in groups:
            group_data = data[data[group_column] == group][value_column]
            if is_normal:
                mean = group_data.mean()
                std = group_data.std()
                row[str(group)] = f"{mean:.2f} Â± {std:.2f}"
            else:
                q1 = group_data.quantile(0.25)
                q3 = group_data.quantile(0.75)
                row[str(group)] = f"({q1:.2f}, {q3:.2f})"

        if len(groups) == 2:
            group1_data = data[data[group_column] == groups[0]][value_column].dropna()
            group2_data = data[data[group_column] == groups[1]][value_column].dropna()
            if is_normal:
                test_stat, p_val = ttest_ind(group1_data, group2_data, equal_var=False)
                test_method = "T-test"
            else:
                test_stat, p_val = kstest(group1_data, group2_data)
                test_method = "Kolmogorov-Smirnov"
        else:
            group_data_list = [data[data[group_column] == group][value_column].dropna() for group in groups]
            if is_normal:
                test_stat, p_val = f_oneway(*group_data_list)
                test_method = "ANOVA"
            else:
                test_stat, p_val = kruskal(*group_data_list)
                test_method = "Kruskal-Wallis"

        row["p-vaule"] = f"{p_val:.4f}"
        row["methods"] = test_method
        results.append(row)

    # å®šå‹å˜é‡å¤„ç†
    for value_column in categorical_columns:
        # æ€»è§ˆè¡Œï¼šåˆå¹¶ä¸ºâ€œæ€»æ•° (100.0%)â€
        total_row = {"variable": f"{value_column} (Total)"}
        for group in groups:
            group_data = data[data[group_column] == group][value_column]
            total = group_data.notna().sum()
            total_row[str(group)] = f"{total} (100.0%)"
        contingency_table = pd.crosstab(data[group_column], data[value_column])
        chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)
        total_row["p-vaule"] = f"{p_val:.4f}"
        total_row["methods"] = "Chi-square"
        results.append(total_row)

        # å­ç±»åˆ«è¡Œ
        categories = sorted(data[value_column].dropna().unique())
        for category in categories:
            row = {"variable": f"{value_column} = {category}"}
            for group in groups:
                group_data = data[(data[group_column] == group) & (data[value_column] == category)]
                count = len(group_data)
                total = len(data[data[group_column] == group])
                percentage = (count / total) * 100 if total > 0 else 0
                row[str(group)] = f"{count} ({percentage:.2f}%)"
            row["p-vaule"] = ""
            row["methods"] = ""
            results.append(row)

    return results

# æ–‡ä»¶ä¸Šä¼ æˆ–ç”Ÿæˆæµ‹è¯•æ•°æ®
uploaded_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆCSVæ ¼å¼ï¼‰", type=["csv"])
if uploaded_file is None:
    st.write("æœªä¸Šä¼ æ–‡ä»¶ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
    data = generate_test_data()
else:
    data = pd.read_csv(uploaded_file)

st.write("æ•°æ®é¢„è§ˆï¼š")
st.write(data.head())

# ç”¨æˆ·é€‰æ‹©å®šé‡å˜é‡
st.write("### é€‰æ‹©å®šé‡å˜é‡")
quantitative_columns = st.multiselect("è¯·é€‰æ‹©å®šé‡å˜é‡åˆ—", data.columns, key="quantitative")

# è‡ªåŠ¨è¯†åˆ«æœªè¢«é€‰ä¸ºå®šé‡çš„åˆ—ä¸ºåˆ†ç±»å˜é‡
auto_categorical_columns = [col for col in data.columns if col not in quantitative_columns]

# è¿‡æ»¤å¯ä½œä¸ºâ€œåˆ†ç»„å˜é‡â€çš„åˆ†ç±»å˜é‡ï¼ˆç±»åˆ«æ•°>=2ï¼‰
group_candidates = [col for col in auto_categorical_columns if data[col].nunique() >= 2]

# æ­£æ€æ€§æ£€éªŒ
if quantitative_columns:
    st.write("### æ­£æ€æ€§æ£€éªŒ")
    for value_column in quantitative_columns:
        method, stat, p_value = normality_test(data, value_column)
        st.write(f"{value_column}ï¼š{method} æ£€éªŒï¼Œç»Ÿè®¡é‡ = {stat:.4f}, p-vaule = {p_value:.4f}")

# é€‰æ‹©åˆ†ç»„å˜é‡ä¸åˆ†æå˜é‡
st.write("### åˆ†ç»„ä¸åˆ†æè®¾ç½®")
group_column = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆåªèƒ½é€‰æ‹©åˆ†ç±»å˜é‡ï¼‰", group_candidates)
#analysis_columns = st.multiselect("é€‰æ‹©åˆ†ææ•°æ®åˆ—", quantitative_columns + auto_categorical_columns)

# åˆæ³•æ€§æ£€æŸ¥
if group_column in quantitative_columns:
    st.error("åˆ†ç»„å˜é‡ä¸èƒ½ä¸ºå®šé‡å˜é‡ï¼")
#elif group_column in analysis_columns:
  #  st.error("åˆ†ç»„å˜é‡ä¸èƒ½åŒæ—¶æ˜¯åˆ†æå˜é‡ï¼")
#elif len(analysis_columns) == 0:
 #   st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æå˜é‡")
else:
    # ä¸‰çº¿è¡¨ç»“æœ
    st.write("### ä¸‰çº¿è¡¨ç»“æœ")
    # è‡ªåŠ¨è¯†åˆ«åˆ†æå˜é‡ï¼ˆæ’é™¤åˆ†ç»„å˜é‡ï¼‰
    analysis_quantitative = [col for col in quantitative_columns if col != group_column]
    analysis_categorical = [col for col in auto_categorical_columns if col != group_column]
    result_table = generate_three_line_table(data, group_column, analysis_quantitative, analysis_categorical)
    styled_table = pd.DataFrame(result_table).style.applymap(highlight_p_value, subset=["p-vaule"])
    st.dataframe(styled_table)

    # å·®å¼‚æ€§åˆ†æ
  #  st.write("### å·®å¼‚æ€§åˆ†æç»“æœ")
  #  analysis_result = difference_analysis(data, group_column, quantitative_columns, auto_categorical_columns)
  #  if analysis_result:
  #      st.dataframe(pd.DataFrame(analysis_result))


    # ä¸‹è½½
    st.write("### ä¸‹è½½ç»“æœ")
    csv = pd.DataFrame(result_table).to_csv(index=False, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½åˆ†æç»“æœ", data=csv, file_name="difference_analysis.csv", mime="text/csv;charset=utf-8-sig")
